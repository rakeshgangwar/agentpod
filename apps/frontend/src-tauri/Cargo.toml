[package]
name = "agentpod"
version = "0.1.0"
description = "Portable Command Center for AI Coding Agents"
authors = ["you"]
edition = "2021"

[lib]
name = "agentpod_lib"
crate-type = ["staticlib", "cdylib", "rlib"]

[build-dependencies]
tauri-build = { version = "2.5.3", features = [] }

[dependencies]
tauri = { version = "2.9.5", features = [] }
tauri-plugin-opener = "2.5.2"
tauri-plugin-dialog = "2.4.2"
tauri-plugin-oauth = "2.0.0"
tauri-plugin-os = "2.3.2"
tauri-plugin-notification = "2.3.3"
tauri-plugin-fs = "2.4.4"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
tokio = { version = "1", features = ["full"] }
tokio-tungstenite = { version = "0.28", features = ["rustls-tls-webpki-roots"] }
http = "1"
# Use rustls with native root certificates for all platforms including Android/iOS
reqwest = { version = "0.12", features = ["json", "rustls-tls-native-roots", "stream", "gzip", "deflate"], default-features = false }
urlencoding = "2"
keyring = "3"
thiserror = "2"
dirs = "6"
chrono = { version = "0.4", features = ["serde"] }
futures = "0.3"
futures-util = "0.3"
rand = "0.8"
sha2 = "0.10"
base64 = "0.22"
once_cell = "1.19"
url = "2.5"
uuid = { version = "1", features = ["v4"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
tauri-plugin-http = "2"

# MCP plugin for AI agent debugging (dev builds only)
tauri-plugin-mcp = { path = "../../../tauri-plugin-mcp" }

# Voice input dependencies (optional)
# Note: On Linux, we use ALSA. The alsa-sys crate will link dynamically by default.
# For static linking (no runtime deps), build with ALSA_STATIC=1 environment variable.
# Most desktop Linux distros have libasound2 pre-installed.
cpal = { version = "0.15", optional = true }                    # Cross-platform audio I/O
hound = { version = "3.5", optional = true }                    # WAV file I/O
whisper-rs = { git = "https://codeberg.org/tazz4843/whisper-rs.git", default-features = false, features = ["tracing_backend"], optional = true }
parking_lot = "0.12"             # Fast synchronization primitives (always needed)
eyre = { version = "0.6", optional = true }                     # Error handling for voice
hf-hub = { version = "0.4", optional = true }                   # Hugging Face model download
# rustpotter - disabled due to candle-core 0.2.2 rand version conflict (requires rand 0.8, half uses rand 0.9)
# Wake word detection now uses OpenWakeWord via ONNX Runtime instead
ort = { version = "2.0.0-rc.9", optional = true }             # ONNX Runtime for wake word detection
ndarray = { version = "0.17", optional = true }               # N-dimensional arrays for ONNX model I/O

[dev-dependencies]
tokio-test = "0.4"
pretty_assertions = "1"
dotenv = "0.15"

[features]
default = []

# Voice input feature (requires system audio libraries: libasound2-dev on Linux, CoreAudio on macOS)
voice = ["cpal", "hound", "whisper-rs", "eyre", "hf-hub", "ort", "ndarray"]

# Voice input GPU acceleration (enable based on target platform)
voice-metal = ["voice", "whisper-rs/metal"]      # macOS GPU acceleration
voice-cuda = ["voice", "whisper-rs/cuda"]        # NVIDIA GPU acceleration
voice-vulkan = ["voice", "whisper-rs/vulkan"]    # Cross-platform GPU (AMD, Intel, etc.)

